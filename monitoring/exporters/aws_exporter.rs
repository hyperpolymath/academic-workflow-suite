use axum::{
    extract::State,
    http::StatusCode,
    response::IntoResponse,
    routing::get,
    Router,
};
use lazy_static::lazy_static;
use prometheus::{
    register_counter, register_counter_vec, register_gauge, register_gauge_vec,
    register_histogram_vec, Counter, CounterVec, Encoder, Gauge, GaugeVec, HistogramVec,
    TextEncoder,
};
use sqlx::{PgPool, Row};
use std::{net::SocketAddr, sync::Arc, time::Duration};
use tokio::time;
use tracing::{error, info};

// Define all custom metrics
lazy_static! {
    // TMA Processing Metrics
    static ref TMA_PROCESSED_TOTAL: CounterVec = register_counter_vec!(
        "aws_tma_processed_total",
        "Total number of TMAs processed",
        &["status"]
    ).unwrap();

    static ref TMA_MARKING_DURATION: HistogramVec = register_histogram_vec!(
        "aws_tma_marking_duration_seconds",
        "Time taken to mark TMAs",
        &["status"],
        vec![1.0, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0]
    ).unwrap();

    static ref TMA_QUEUE_DEPTH: Gauge = register_gauge!(
        "aws_tma_queue_depth",
        "Number of TMAs waiting to be processed"
    ).unwrap();

    static ref BATCH_TMA_PROCESSED: Counter = register_counter!(
        "aws_batch_tma_processed_total",
        "Total TMAs processed in batch mode"
    ).unwrap();

    // Feedback Quality Metrics
    static ref FEEDBACK_QUALITY_SCORE: Gauge = register_gauge!(
        "aws_feedback_quality_score",
        "Average feedback quality score (0-1)"
    ).unwrap();

    // AI Performance Metrics
    static ref AI_INFERENCE_DURATION: HistogramVec = register_histogram_vec!(
        "aws_ai_inference_duration_seconds",
        "AI inference duration",
        &["model"],
        vec![0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
    ).unwrap();

    static ref AI_INFERENCE_TOTAL: CounterVec = register_counter_vec!(
        "aws_ai_inference_total",
        "Total AI inferences",
        &["model", "status"]
    ).unwrap();

    static ref AI_TOKENS_GENERATED: CounterVec = register_counter_vec!(
        "aws_ai_tokens_generated_total",
        "Total tokens generated by AI",
        &["model"]
    ).unwrap();

    static ref MODEL_LOADING_DURATION: Gauge = register_gauge!(
        "aws_model_loading_duration_seconds",
        "Time taken to load AI model"
    ).unwrap();

    static ref AI_QUEUE_DEPTH: Gauge = register_gauge!(
        "aws_ai_queue_depth",
        "Number of AI inference requests in queue"
    ).unwrap();

    static ref MODEL_LOADED: Gauge = register_gauge!(
        "aws_model_loaded",
        "Whether AI model is loaded (1=loaded, 0=not loaded)"
    ).unwrap();

    // GPU Metrics
    static ref GPU_MEMORY_USED: Gauge = register_gauge!(
        "aws_gpu_memory_used_bytes",
        "GPU memory used in bytes"
    ).unwrap();

    static ref GPU_MEMORY_TOTAL: Gauge = register_gauge!(
        "aws_gpu_memory_total_bytes",
        "Total GPU memory in bytes"
    ).unwrap();

    static ref GPU_UTILIZATION: Gauge = register_gauge!(
        "aws_gpu_utilization_percent",
        "GPU utilization percentage"
    ).unwrap();

    static ref GPU_TEMPERATURE: Gauge = register_gauge!(
        "aws_gpu_temperature_celsius",
        "GPU temperature in Celsius"
    ).unwrap();

    // Event Store Metrics
    static ref EVENT_STORE_TOTAL_EVENTS: Gauge = register_gauge!(
        "aws_event_store_total_events",
        "Total number of events in event store"
    ).unwrap();

    // User Metrics
    static ref ACTIVE_USERS: Gauge = register_gauge!(
        "aws_active_users",
        "Number of active users"
    ).unwrap();

    // Security Metrics
    static ref AUTH_FAILED: CounterVec = register_counter_vec!(
        "aws_auth_failed_total",
        "Failed authentication attempts",
        &["reason", "ip"]
    ).unwrap();

    static ref PII_DETECTED: CounterVec = register_counter_vec!(
        "aws_pii_detected_total",
        "PII detection events",
        &["type"]
    ).unwrap();

    static ref CONTAINER_ESCAPE_ATTEMPTS: CounterVec = register_counter_vec!(
        "aws_container_escape_attempts_total",
        "Container escape attempts",
        &["method", "container"]
    ).unwrap();

    static ref AUDIT_LOG_ENTRIES: CounterVec = register_counter_vec!(
        "aws_audit_log_entries_total",
        "Audit log entries",
        &["action", "user"]
    ).unwrap();

    static ref SECURITY_EVENTS: CounterVec = register_counter_vec!(
        "aws_security_events_total",
        "Security events",
        &["type", "severity"]
    ).unwrap();

    static ref RATE_LIMIT_ACTIVE_BLOCKS: Gauge = register_gauge!(
        "aws_rate_limit_active_blocks",
        "Number of active rate limit blocks"
    ).unwrap();

    static ref RATE_LIMIT_EXCEEDED: CounterVec = register_counter_vec!(
        "aws_rate_limit_exceeded_total",
        "Rate limit violations",
        &["endpoint", "ip"]
    ).unwrap();
}

#[derive(Clone)]
struct AppState {
    db_pool: PgPool,
}

/// Collect TMA processing metrics from database
async fn collect_tma_metrics(pool: &PgPool) -> anyhow::Result<()> {
    // Get TMA queue depth
    let queue_depth: i64 = sqlx::query_scalar(
        "SELECT COUNT(*) FROM tmas WHERE status = 'pending'"
    )
    .fetch_one(pool)
    .await?;
    TMA_QUEUE_DEPTH.set(queue_depth as f64);

    // Get average feedback quality
    let avg_quality: Option<f64> = sqlx::query_scalar(
        "SELECT AVG(quality_score) FROM feedback WHERE created_at > NOW() - INTERVAL '1 hour'"
    )
    .fetch_one(pool)
    .await?;
    if let Some(quality) = avg_quality {
        FEEDBACK_QUALITY_SCORE.set(quality);
    }

    // Get TMA processing stats
    let stats = sqlx::query(
        "SELECT status, COUNT(*) as count FROM tmas WHERE created_at > NOW() - INTERVAL '1 hour' GROUP BY status"
    )
    .fetch_all(pool)
    .await?;

    for row in stats {
        let status: String = row.get("status");
        let count: i64 = row.get("count");
        TMA_PROCESSED_TOTAL
            .with_label_values(&[&status])
            .inc_by(count as f64);
    }

    Ok(())
}

/// Collect AI performance metrics
async fn collect_ai_metrics(pool: &PgPool) -> anyhow::Result<()> {
    // Get AI queue depth
    let ai_queue: i64 = sqlx::query_scalar(
        "SELECT COUNT(*) FROM ai_inference_queue WHERE status = 'pending'"
    )
    .fetch_one(pool)
    .await?;
    AI_QUEUE_DEPTH.set(ai_queue as f64);

    // Get model status
    let model_loaded: bool = sqlx::query_scalar(
        "SELECT EXISTS(SELECT 1 FROM ai_models WHERE status = 'loaded')"
    )
    .fetch_one(pool)
    .await?;
    MODEL_LOADED.set(if model_loaded { 1.0 } else { 0.0 });

    // Simulate GPU metrics (in production, these would come from nvidia-smi or similar)
    // For now, we'll query from a hypothetical gpu_metrics table
    if let Ok(gpu_mem_used) = sqlx::query_scalar::<_, i64>(
        "SELECT memory_used FROM gpu_metrics ORDER BY timestamp DESC LIMIT 1"
    )
    .fetch_one(pool)
    .await
    {
        GPU_MEMORY_USED.set(gpu_mem_used as f64);
    }

    if let Ok(gpu_mem_total) = sqlx::query_scalar::<_, i64>(
        "SELECT memory_total FROM gpu_metrics ORDER BY timestamp DESC LIMIT 1"
    )
    .fetch_one(pool)
    .await
    {
        GPU_MEMORY_TOTAL.set(gpu_mem_total as f64);
    }

    Ok(())
}

/// Collect event store metrics
async fn collect_event_store_metrics(pool: &PgPool) -> anyhow::Result<()> {
    let total_events: i64 = sqlx::query_scalar(
        "SELECT COUNT(*) FROM events"
    )
    .fetch_one(pool)
    .await?;
    EVENT_STORE_TOTAL_EVENTS.set(total_events as f64);

    Ok(())
}

/// Collect user metrics
async fn collect_user_metrics(pool: &PgPool) -> anyhow::Result<()> {
    let active_users: i64 = sqlx::query_scalar(
        "SELECT COUNT(DISTINCT user_id) FROM sessions WHERE last_activity > NOW() - INTERVAL '15 minutes'"
    )
    .fetch_one(pool)
    .await?;
    ACTIVE_USERS.set(active_users as f64);

    Ok(())
}

/// Collect security metrics
async fn collect_security_metrics(pool: &PgPool) -> anyhow::Result<()> {
    // Get failed auth attempts by reason
    let auth_failures = sqlx::query(
        "SELECT reason, source_ip, COUNT(*) as count
         FROM auth_failures
         WHERE created_at > NOW() - INTERVAL '5 minutes'
         GROUP BY reason, source_ip"
    )
    .fetch_all(pool)
    .await?;

    for row in auth_failures {
        let reason: String = row.get("reason");
        let ip: String = row.get("source_ip");
        let count: i64 = row.get("count");
        AUTH_FAILED
            .with_label_values(&[&reason, &ip])
            .inc_by(count as f64);
    }

    // Get active rate limit blocks
    let rate_limit_blocks: i64 = sqlx::query_scalar(
        "SELECT COUNT(*) FROM rate_limit_blocks WHERE expires_at > NOW()"
    )
    .fetch_one(pool)
    .await?;
    RATE_LIMIT_ACTIVE_BLOCKS.set(rate_limit_blocks as f64);

    Ok(())
}

/// Background task to collect metrics periodically
async fn metrics_collector(state: Arc<AppState>) {
    let mut interval = time::interval(Duration::from_secs(15));

    loop {
        interval.tick().await;

        if let Err(e) = collect_tma_metrics(&state.db_pool).await {
            error!("Failed to collect TMA metrics: {}", e);
        }

        if let Err(e) = collect_ai_metrics(&state.db_pool).await {
            error!("Failed to collect AI metrics: {}", e);
        }

        if let Err(e) = collect_event_store_metrics(&state.db_pool).await {
            error!("Failed to collect event store metrics: {}", e);
        }

        if let Err(e) = collect_user_metrics(&state.db_pool).await {
            error!("Failed to collect user metrics: {}", e);
        }

        if let Err(e) = collect_security_metrics(&state.db_pool).await {
            error!("Failed to collect security metrics: {}", e);
        }
    }
}

/// Metrics endpoint handler
async fn metrics_handler() -> impl IntoResponse {
    let encoder = TextEncoder::new();
    let metric_families = prometheus::gather();
    let mut buffer = Vec::new();

    match encoder.encode(&metric_families, &mut buffer) {
        Ok(_) => (
            StatusCode::OK,
            [(axum::http::header::CONTENT_TYPE, "text/plain; charset=utf-8")],
            buffer,
        ),
        Err(e) => {
            error!("Failed to encode metrics: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                [(axum::http::header::CONTENT_TYPE, "text/plain; charset=utf-8")],
                format!("Failed to encode metrics: {}", e).into_bytes(),
            )
        }
    }
}

/// Health check endpoint
async fn health_handler(State(state): State<Arc<AppState>>) -> impl IntoResponse {
    match sqlx::query("SELECT 1").fetch_one(&state.db_pool).await {
        Ok(_) => (StatusCode::OK, "OK"),
        Err(e) => {
            error!("Health check failed: {}", e);
            (StatusCode::SERVICE_UNAVAILABLE, "Database connection failed")
        }
    }
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt::init();

    // Load environment variables
    dotenvy::dotenv().ok();

    // Get database URL from environment
    let database_url = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "postgres://localhost/academic_workflow_suite".to_string());

    // Create database connection pool
    info!("Connecting to database: {}", database_url);
    let db_pool = PgPool::connect(&database_url).await?;

    // Create application state
    let state = Arc::new(AppState { db_pool });

    // Start metrics collector background task
    let collector_state = state.clone();
    tokio::spawn(async move {
        metrics_collector(collector_state).await;
    });

    // Build router
    let app = Router::new()
        .route("/metrics", get(metrics_handler))
        .route("/health", get(health_handler))
        .with_state(state);

    // Bind to address
    let addr = SocketAddr::from(([0, 0, 0, 0], 9090));
    info!("Starting AWS metrics exporter on {}", addr);

    // Start server
    let listener = tokio::net::TcpListener::bind(addr).await?;
    axum::serve(listener, app).await?;

    Ok(())
}
